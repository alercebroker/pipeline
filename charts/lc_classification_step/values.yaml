# Default values for step_starter.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

namespace: lc-classifier-step

image:
  repository: ghcr.io/alercebroker/lc_classifier_step
  pullPolicy: Always
  # Overrides the image tag whose default is the chart appVersion.
  tag: ""

imagePullSecrets:
  - name: "image-pull-access"
nameOverride: ""
fullnameOverride: ""

podAnnotations: {}

service:
  type: ClusterIP
  port: 8000

resources: {}

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 4
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

affinity:
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
          - matchExpressions:
            - key: eks.amazonaws.com/nodegroup
              operator: In
              ## Override this value with the NodeGroup tag accordingly
              values: []

configmap:
  consumerTopics: ""
  consumerGroup: ""
  publicServer: ""
  internalServer: ""
  scribeTopic: ""
  metricsTopic: ""
  consumeTimeout: "10"
  consumeMessages: "100"
  kafka:
    securityProtocol: "SASL_SSL"
    saslMechanism: "SCRAM-SHA-512"
  # Stream can be one of elasticc or ztf
  stream: "ztf"
  # The path to the model
  modelPath: ""
  # Optional path to header quantiles files
  # Used by Balto, Messi and Barney models
  quantilesPath: ""
  # Optional path to feature quantiles files
  # Used by Messi model
  featureQuantilesPath: ""
  # This is the actual model implementation version
  modelVersion: ""
  # The class within the step module used for the predictor
  # This will begin with lc_classification.predictors
  # It should be the full module path to the predictor class
  # so something like module.submodule.ClassName
  modelClass: "lc_classification.predictors.ztf_random_forest.ztf_random_forest_predictor.ZtfRandomForestPredictor"
  mapperClass: ""
  # Same as the predictorClass but for the scribe parser
  # Probably no need to change this
  scribeParserClass: "lc_classification.core.parsers.scribe_parser.ScribeParser"
  # Same as predictorClass but for the step output parser
  # This could be one output for the regular ALeRCE output or one for the ELASTICC stream output
  # The regular ALeRCE output is the default
  stepParserClass: "lc_classification.core.parsers.alerce_parser.AlerceParser"
  producerClass: "apf.producers.kafka.KafkaProducer"
  producerTopicFormat: "lc_classifier_%s"
  producerDateFormat: "%Y%m%d"
  producerChangeHour: "23"

secrets:
  kafkaAuth:
    consumer:
      enabled: false
      username: ""
      password: ""
    producer:
      enabled: false
      username: ""
      password: ""
    metrics:
      enabled: false
      username: ""
      password: ""
    scribe:
      enabled: false
      username: ""
      password: ""

imageCredentials:
  registry: ""
  username: ""
  password: ""
  email: ""

extraEnvVariables:
  ## - name: METRICS_SOURCE
  ##   value: {{ .Release.Name }}
  ## - name: METRICS_SURVEY
  ##   value: ATLAS
