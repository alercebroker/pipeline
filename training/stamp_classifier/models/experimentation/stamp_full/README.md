### Stamp Classifier - Entrenamiento y Evaluaci贸n

Este proyecto contiene el pipeline de procesamiento y entrenamiento para un clasificador de recortes astron贸micos (stamps).

---

###  Preparaci贸n de los datos

Primero, se deben obtener los datos desde el servidor remoto ejecutando:

```bash
scp -r quimal_gpu:/storage/multilevel_stamp_classifier_data_wo_carrasco_davis/consolidated_dataset.pkl \
/home/dmoreno/pipeline_v4_final/pipeline/training/stamp_classifier/data_acquisition/data/processed

scp -r quimal_gpu:/storage/multilevel_stamp_classifier_data_wo_carrasco_davis/consolidated_dataset_avro.pkl \
/home/dmoreno/pipeline_v4_final/pipeline/training/stamp_classifier/data_acquisition/data/processed

scp -r quimal_gpu:/storage/full_stamp_classifier/full_stamp_classifier_metadata_hasavro.parquet \
/home/dmoreno/pipeline_v4_final/pipeline/training/stamp_classifier/models/experimentation/stamp_full/data

scp -r quimal_gpu:/storage/full_stamp_classifier/full_stamp_classifier_metadata_noavro.parquet \
/home/dmoreno/pipeline_v4_final/pipeline/training/stamp_classifier/models/experimentation/stamp_full/data

```

Luego, ub铆cate en el directorio de experimentaci贸n:

```bash
cd /home/dmoreno/pipeline_v4_final/pipeline/training/stamp_classifier/models/experimentation/stamp_full
```

Ejecuta el script de procesamiento:

```bash
python data_processor.py
```

Este paso genera dos archivos en la carpeta `data/`, ya divididos en conjuntos de entrenamiento, validaci贸n y test:

* `consolidated_ndarrays.pkl` (paso previo al normalizado)
* `normalized_ndarrays.pkl` (archivo final que se usa para entrenar)

o bien,

* `consolidated_ndarrays_avro.pkl` (paso previo al normalizado)
* `normalized_ndarrays_avro.pkl` (archivo final que se usa para entrenar)

esto depende de la configuracion que se use al final del script `data_processor.py`, por default solo se ocuparan los datos que tienen avro.

---

###  Entrenamiento del modelo

Utilizamos el archivo `normalized_ndarrays*.pkl` o  para entrenar el modelo:

```bash
python train_and_save_best_models.py
```

o bien, usa los bash que estan creados en el path `bash/all_classes_v1`. Tambien puedes ponerlos en el `run_all.sh`.

Este proceso tambi茅n genera logs compatibles con TensorBoard, donde se pueden visualizar las curvas de aprendizaje en t茅rminos de:

* F1-score
* Loss
* Accuracy

Para visualizar los resultados:

```bash
tensorboard --logdir=run_0/logs --port=6006
```

Y si est谩s en un servidor remoto, puedes hacer un reenv铆o de puerto (port forwarding) desde tu m谩quina local:

```bash
ssh -N -L 6006:localhost:6006 dmoreno@quimal-gpu
```

Abre luego en tu navegador:

```
http://localhost:6006
```

---

###  Evaluaci贸n del modelo

Para evaluar el modelo y generar la matriz de confusi贸n, se puede usar el notebook:

```
data/inference.ipynb
```

> 锔 **Nota:** El notebook no est谩 completamente ordenado, por lo que se recomienda revisarlo con atenci贸n para entender qu茅 hace cada celda.

---

Para dudas o mejoras, por favor revisar el c贸digo y documentaci贸n correspondiente.
