hydra:
  run:
    dir: .
  output_subdir: null 

stamp_classifier:
  results_dir: 'results_rubin'
  exp_description: ''
  
  # Load pretrained model
  load_pretrained_model: false
  checkpoint: {
    exp_name: classification/ztf/testing,
    run_name: 2025-09-25_13-18-27,
    results_dir: results_ztf
  }

  # General Configuration
  model_name: 'stamp_full' # no usado
  name_dataset_version: 'rubin'
  dir_data: './../../../data_acquisition/rubin/data/processed/ts_stamps_v0.0.4_dp1/'
  path_partition: './../../../data_acquisition/rubin/data/processed/partitions/ts_stamps_v0.0.4_dp1_undersampling/partitions.parquet'
  #dir_data: './../../../data_acquisition/rubin/data/processed/ztf_as_rubin_v0.0/'
  #path_partition: './../../../data_acquisition/rubin/data/processed/partitions/ztf_as_rubin_v0.0/partitions.parquet'
  #dir_data: './../../../data_acquisition/rubin/data/processed/rubin_5_classes2/ts_stamps_v0.0.3_dp1/'
  #path_partition: './../../../data_acquisition/rubin/data/processed/partitions/rubin_5_classes2/partitions.parquet'
  list_folds: [0, 1, 2, 3, 4]
  debug: false
  is_searching_hyperparameters: true

  # Loaders Configuration
  loader:
    id_col: 'diaObjectId'
    candid_col: 'diaSourceId'
    ra_col: 'ra'
    dec_col: 'dec'
    class_col: 'class'
    stamps_cols: ['visit_image', 'difference_image', 'reference_image']
    cropping: {
      use: false,
      crop_size: 21
    }
    num_workers: 12 # No lo estoy usando
    coord_type: 'spherical' # ['spherical', 'cartesian']
    norm_type: 'z-score' # ['qt', 'z-score']
    batch_size: 256
    use_coords: false
    
  arch:
    conv_config:
      - filters: 8
        kernel_size: [2, 2]
        activation: relu
        pool: false
        pool_size: [2, 2]

      - filters: 16
        kernel_size: [2, 2]
        activation: relu
        pool: true
        pool_size: [2, 2]

      - filters: 8
        kernel_size: [2, 2]
        activation: relu
        pool: false
        pool_size: [2, 2]

      - filters: 16
        kernel_size: [2, 2]
        activation: relu
        pool: true
        pool_size: [2, 2]

      #- filters: 8
      #  kernel_size: [2, 2]
      #  activation: relu
      #  pool: true
      #  pool_size: [2, 2]
        #batchnorm: true

    dense_config:
      - units: 16
        activation: tanh

    dropout_rate: 0.7
    use_batchnorm_metadata: false
    use_metadata: false

  # Training Configuration
  training:
    lr: 0.0007
    #7589
    use_focal: false    
    patience: 10
    num_epochs: 10000
    monitor: 'loss'
    eval_train_at_the_epoch_end: true
